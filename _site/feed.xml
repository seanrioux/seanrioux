<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2021-01-18T22:07:03-05:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Sean Rioux</title><subtitle>This is it. This is a blog template and it's tight. Seriously, it's got everything it needs. Got it. Good.</subtitle><entry><title type="html">How To Fix The Web: Ban The Bots</title><link href="http://localhost:4000/article/2019-02-04-ban-all-bots" rel="alternate" type="text/html" title="How To Fix The Web: Ban The Bots" /><published>2019-02-04T00:00:00-05:00</published><updated>2019-02-04T00:00:00-05:00</updated><id>http://localhost:4000/article/ban-all-bots</id><content type="html" xml:base="http://localhost:4000/article/2019-02-04-ban-all-bots">&lt;p&gt;Social media is inundated with bots engaged in platform manipulation. These bots
are programmed to amplify harmful discourse, sow polarization, and as we have
seen already this year, lead to real world chaos.&lt;/p&gt;

&lt;p&gt;Despite violent attacks on democracy social media platforms continue to manage
the problem reactively, if not retroactively. Mass culling of accounts after
real world harm occurs is not a sustainable solution. Platforms need to begin to
act proactively, restrictively, and on multiple fronts to battle manipulation.&lt;/p&gt;

&lt;p&gt;This means a change to their incentives, and their business fundamentals, and it
will cost them. In the meantime, as misinformation continues to draw out this
global pandemic, as blood is shed on the steps of the US capital building, what
are their continued half measures costing us?&lt;/p&gt;

&lt;h3 id=&quot;scale&quot;&gt;Scale&lt;/h3&gt;

&lt;p&gt;The scale of this issue is global. Some truly humbling numbers:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A 2017 study estimated that 9%-15% of Twitter accounts were bots&lt;/li&gt;
  &lt;li&gt;A 2019 CNN report found Facebook removed 5.4 billion fake accounts&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.npr.org/sections/coronavirus-live-updates/2020/05/20/859814085/researchers-nearly-half-of-accounts-tweeting-about-coronavirus-are-likely-bots&quot;&gt;Nearly half of accounts Tweeting about Coronavirus are likely bots&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;impact&quot;&gt;Impact&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.nature.com/articles/d41586-020-03034-5&quot;&gt;The next-generation bots interfering with the US election&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.npr.org/sections/coronavirus-live-updates/2020/05/20/859814085/researchers-nearly-half-of-accounts-tweeting-about-coronavirus-are-likely-bots&quot;&gt;Researchers: Nearly Half Of Accounts Tweeting About Coronavirus Are Likely Bots&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.nationalobserver.com/2019/06/26/news/non-human-users-threaten-hijack-canadas-twitter-discussions&quot;&gt;Non-human users threaten to hijack Canada’s Twitter discussions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;causes&quot;&gt;Causes&lt;/h2&gt;

&lt;p&gt;When we consider platform mechanics and business incentives we find many
possible factors:&lt;/p&gt;

&lt;h3 id=&quot;prioritizing-user-volume&quot;&gt;Prioritizing user volume&lt;/h3&gt;

&lt;p&gt;From the beginning social platforms have prioritized user volume. As publicly
traded companies, with revenue tied to advertising, pressure on upward user
growth is primary. This pursuit of user led-growth has lead to a general
industry goal of low friction sign-up, so low, that the process can be easily
automated for most services.&lt;/p&gt;

&lt;p&gt;Furthermore, it is possible correlating user growth and revenue acts as a
perverse incentive; leading companies to ignore fake users, in the interest of
inflated growth metrics.&lt;/p&gt;

&lt;h3 id=&quot;lack-of-user-verification&quot;&gt;Lack of user verification&lt;/h3&gt;

&lt;p&gt;In pursuit of low friction sign-up, these services have resisted more effective
user verification measures. While many services has recently begun to encourage
two factor authentication or offer voluntary verification programs, for the
general user no more than an email is a required to sign-up for most.&lt;/p&gt;

&lt;p&gt;This is problematic. Email is not as a reliable indicator of authentic activity
as an email server can be hosted anywhere, and accounts created on mass via
automation.&lt;/p&gt;

&lt;h3 id=&quot;interaction-via-api&quot;&gt;Interaction via API&lt;/h3&gt;

&lt;p&gt;As human users of Twitter we use an app or the web interface. An API, (or
application programming interface) allows programmers to build software
automation to interact with the service, also known. Depending on the service,
these bots can do close to everything that is possible through the app or web
interface, but without the limitations of the user interface or a human user:
bots can work faster, more efficiently, and around the clock.&lt;/p&gt;

&lt;p&gt;Why would they allow this you might ask? The purpose of an social API is to
allow third-party businesses to leverage the platforms to build new products and
services. If you use Buffer or Hootsuite, for example, you’re leveraging APIs.&lt;/p&gt;

&lt;p&gt;While perhaps beneficial in these applications, these same APIs may also be
exploited by bad actors. Furthermore, sorting legitimate and illegitimate use is
a non-trivial task, inevitably requiring human moderation for millions, if not
billions of individual automated interactions.&lt;/p&gt;

&lt;p&gt;Most problematically, perhaps, user are typically not even aware this automation
is possible or prevalent, meaning legitimate or not, many of us are interacting
with automated content opaquely (i.e., we have no indication that we are
interacting with an API driven automation).&lt;/p&gt;

&lt;h2 id=&quot;possible-platform-solutions&quot;&gt;Possible platform solutions&lt;/h2&gt;

&lt;p&gt;As Jack Dorsey was apt to point out in a recent interview on the New York Times
Daily podcast, there is no magic bullet to solving the issues of social media
and changes must be carefully considered. For the most part the fundamental
mechanisms of these platforms were not designed with a great deal of
consideration for their broad social impact. Learning from that mistake, it is
essential as we consider any change to these platforms carefully to mitigate
future negative impact.&lt;/p&gt;

&lt;p&gt;This, however, cannot be used as an excuse for inaction, or more importantly
deep changes. This is where it is important for these companies to have the
courage to challenges deeply held assumptions inherent to the their businesses,
and the web. Things like the inherent anonymity of the web, and business models
that rely on quantity over quality must be challenged, considered and discussed
openly.&lt;/p&gt;

&lt;h3 id=&quot;verify-every-account&quot;&gt;Verify every account&lt;/h3&gt;

&lt;p&gt;Starting with new registrations and working through all accounts, all social
media accounts should be verified, and determined to be held by a specific
individual. While services might opt to allow unverified accounts, these
accounts should be flagged as unverified (similar to the current Twitter
verified badge) to ensure humans are clearly able to delineate between trusted
human sources, and possible non-human actors on the platform.&lt;/p&gt;

&lt;p&gt;There are a few methods that could be used here (some already in practice for
access to certain features) either in tandem or as part of a suite of possible
options:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;SMS based verification:&lt;/strong&gt; a user receives an SMS containing a unique code on
registration, which they use, in conjunction with their password, to access
the service and on every subsequent sign-in (i.e., two factor authentication).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Government issued ID verification:&lt;/strong&gt; a user submits a photo of a valid
government issued ID which is checked for authenticity and uniqueness.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Human profile photo verification:&lt;/strong&gt; a user must maintain at least one well
lit, machine and human identifiable image of their face (ideally matching that
of the ID).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Peer verification:&lt;/strong&gt; a new user may request verification from peers who are
verified on the service to confirm their identity.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Address verification:&lt;/strong&gt; a new user must submit a mailing address to which
they have access. The user receives a postcard from the service to that
address, which includes return postage. The user signs the postcard, and mails
it back confirming their address.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Payment with a credit card:&lt;/strong&gt; perhaps the least popular, but one of the most
effective and trusted methods would be simply to require users to pay, a one
time fee, to process a verification (with a credit card in their name).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To some these verifications might seem draconian (though most, if not all are
already a part of official verification policies). To some they might present
privacy concerns. What about users seeking to hide their identities (or example,
whistle-blowers or other anonymous actors)? To that I would argue, that without
a method to properly verify these individuals are who they say they are, that
anonymity does more harm than good on these type of platforms.&lt;/p&gt;

&lt;p&gt;The traditional news media has long had policies and methods for verifying
anonymous sources as trusted, privately, in ways that protect the source but
allow them to publish information they assert as truthful. Self published
information from anonymous sources is unverifiable, and thus objectively,
untrustworthy.&lt;/p&gt;

&lt;p&gt;One account per individual If we are to require verification for each account,
the natural conclusion is that only one personal account may be held by each
human individual. The operative here is personal account, namely that each human
user on these services should be presented as such, and verified as such to be
trustworthy.&lt;/p&gt;

&lt;p&gt;There is, of course, a legitimate use case for engaging via multiple accounts on
social media, for example engaging as a business, organization, or a creator. In
these cases additional verification measure can be employed. Should the entity
hold special designation (for example, they are a registered LLC or hold a
trademark) that this special designation can be submitted for verification, and
be identified (e.g., as a badge) in the account profile to build trust.&lt;/p&gt;

&lt;p&gt;In cases where this is not so, for example when an account is simply for a blog,
or other creator without any sort of incorporation of registration of business
then the restriction is simple: these accounts can still be maintained, but will
lack badges of verification. Once these creators become established and
officially designated in some verifiable way they can then apply for
verification and improve their standing.&lt;/p&gt;

&lt;p&gt;The goal should be that verification, or special badges of designation should
indicate trust not truth per se, but traceability back to human actors. In this
capacity badges of verification should be prominent, displayed on every post,
every profile, every interface.&lt;/p&gt;

&lt;h3 id=&quot;restrict-activity-for-unverified-accounts&quot;&gt;Restrict activity for unverified accounts&lt;/h3&gt;

&lt;p&gt;As not all accounts will chose to verify (and of course, some may be unable to)
activity for these accounts should be restricted. This should act as both an
incentive for verification, to encourage verification, but also, to marginalize
possible non-human actors who are unable to verify.&lt;/p&gt;

&lt;p&gt;A number of possible restrictions might have effect:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Restrict frequency of posting:&lt;/strong&gt; reduce the rate at which unverified users
are able to post to the site (e.g., by the minute or even by the hour).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Restrict or demote unverified comments:&lt;/strong&gt; reduce the prominence or
visibility of comments (or other interactions) made by unverified accounts. If
you want your voice to be heard, you need a face.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Restrict what they can see:&lt;/strong&gt; most effectively perhaps (if not sure to be
most controversial), limit the amount of content a user can access if
unverified. Restrict them to only verified publishers, limit their feed,
whatever it takes to create value incentives to verify.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;One might make the point, that many social users (if not most on Twitter and
Instagram), are passive users who would not inclined to verify. These users
might simply leave or accept a restricted experience, reducing their usage. This
could amount to a massive loss of revenue to these platforms, as ad revenue is
paired to audience size, and the time people spend on these platforms (both
toxic key metrics we’ll explore in a future post).&lt;/p&gt;

&lt;p&gt;But, as an ad buyer, I can’t help but wonder, how much of my ad spend goes to
non-human actors ignore my ads? If there not more value to a verified audience?&lt;/p&gt;

&lt;p&gt;Fundamentally it’s a question quality versus quantity. These platforms may have
been built on quantity, but if quantity is artificial it’s value is lost both to
us as users and to advertisers. Refocusing to be providers of greater quality
(or at least more verifiably human) engage is a value incentive on both fronts,
even if it changes the business metrics.&lt;/p&gt;

&lt;p&gt;And that’s the key point isn’t it? Incentives. Restrictions may be perceived as
negative incentives, but if there is no or insufficient incentive to overcome a
barrier to entry (like being verified), then this likely reflects a flimsy value
proposition. “Easy sign-up” is not a point of value, it’s a user experience
optimization, and so what are humans getting when we give in to these platforms?&lt;/p&gt;

&lt;p&gt;So as we consider restrictions, we must also consider how these platforms can
increase the value on offer. Do so, and users will choose to look past
restrictions, and verify.&lt;/p&gt;

&lt;h3 id=&quot;flag-artificial-interactions&quot;&gt;Flag artificial interactions&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Flag all content posted via API&lt;/li&gt;
  &lt;li&gt;Flag possible artificial content
    &lt;ul&gt;
      &lt;li&gt;Content which is duplicitous:&lt;/li&gt;
      &lt;li&gt;Content which has been flagged as artificial:&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;empower-user-moderation&quot;&gt;Empower user moderation&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Create a moderator team:&lt;/li&gt;
  &lt;li&gt;Respond more actively via flagging:&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;whats-coming&quot;&gt;What’s coming&lt;/h2&gt;

&lt;p&gt;No-one is prepared for how disruptive artificial intelligence is to become in
the coming decade. and in this case social media companies have done little to
moderate their possible use in developing next generation bots.&lt;/p&gt;

&lt;p&gt;At the moment, the non-human actors we’re considering here are simple automated
bots, designed to mimic human interaction.&lt;/p&gt;

&lt;p&gt;However, if we look at the field of machine learning, and the ease at which deep
fakes can produce fake human profile images, video, audio, or how bots can be
trained to create original and convincing written text, and the problem of these
non-human actors owning may become intractable.&lt;/p&gt;

&lt;p&gt;This is why I’m recommending a few premptive actions:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Ban AI generated content&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This it’s why companies act now: to work to ban any and all automated activity,
and to allow human communications to be human scale.&lt;/p&gt;</content><author><name>Sean Rioux</name></author><category term="web" /><summary type="html">Social media is inundated with bots engaged in platform manipulation. These bots are programmed to amplify harmful discourse, sow polarization, and as we have seen already this year, lead to real world chaos.</summary></entry></feed>